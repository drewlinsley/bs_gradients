{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b69f5c-18fd-419b-a640-b26740605dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///gpfs/data/tserre/irodri15/Brainscore/serre_repos/bs_hackathon/model-tools\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: h5py in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from model-tools==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: Pillow in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from model-tools==0.1.0) (8.4.0)\n",
      "Requirement already satisfied: numpy in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from model-tools==0.1.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages/tqdm-4.64.0-py3.6.egg (from model-tools==0.1.0) (4.64.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |█████████████▏                  | 362.0 MB 107.9 MB/s eta 0:00:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 881.9 MB 47 kB/s               \n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 28.3 MB/s            \n",
      "\u001b[?25hCollecting tensorflow==1.15\n",
      "  Downloading tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3 MB)\n",
      "     |████████████████████████████████| 412.3 MB 174 kB/s             \n",
      "\u001b[?25hCollecting keras==2.3.1\n",
      "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "     |████████████████████████████████| 377 kB 93.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from model-tools==0.1.0) (0.24.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from keras==2.3.1->model-tools==0.1.0) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from keras==2.3.1->model-tools==0.1.0) (6.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from keras==2.3.1->model-tools==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from keras==2.3.1->model-tools==0.1.0) (1.1.2)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "     |████████████████████████████████| 50 kB 14.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (1.46.3)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "     |████████████████████████████████| 503 kB 100.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (1.1.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "     |████████████████████████████████| 3.8 MB 98.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (0.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorflow==1.15->model-tools==0.1.0) (3.19.4)\n",
      "Requirement already satisfied: cached-property in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from h5py->model-tools==0.1.0) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from scikit-learn->model-tools==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from scikit-learn->model-tools==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from torch->model-tools==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from torch->model-tools==0.1.0) (0.8)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 43 kB/s               \n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages/importlib_resources-5.7.1-py3.6.egg (from tqdm->model-tools==0.1.0) (5.7.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->model-tools==0.1.0) (57.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->model-tools==0.1.0) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->model-tools==0.1.0) (3.3.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from importlib-resources->tqdm->model-tools==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->model-tools==0.1.0) (4.8.3)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=79ae8e967dd500483772263438631fc4e4e314a72c8b2c753222a295e83f7c5d\n",
      "  Stored in directory: /gpfs/home/irodri15/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "Successfully built gast\n",
      "Installing collected packages: torch, tensorflow-estimator, tensorboard, keras-applications, gast, astor, torchvision, tensorflow, keras, model-tools\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.6.0\n",
      "    Uninstalling tensorboard-2.6.0:\n",
      "      Successfully uninstalled tensorboard-2.6.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.2\n",
      "    Uninstalling tensorflow-2.6.2:\n",
      "      Successfully uninstalled tensorflow-2.6.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Running setup.py develop for model-tools\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 keras-2.3.1 keras-applications-1.0.8 model-tools-0.1.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 torch-1.10.1 torchvision-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -e model-tools/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lookup from /gpfs/data/tserre/irodri15/Brainscore/venv_bs/lib/python3.6/site-packages/brainio_collection-0.1.0-py3.6.egg/brainio_collection/lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/tserre/irodri15/Brainscore/original_repos/brain-score/brainscore/metrics/__init__.py:37: FutureWarning: xarray subclass Score should explicitly define __slots__\n",
      "  class Score(DataAssembly):\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'candidate_models.model_commitments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7801ba308dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrainscore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscore_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_transformation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayerMappedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTemporalIgnore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcandidate_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_commitments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbrain_translated_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'candidate_models.model_commitments'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from brainscore import score_model\n",
    "from model_tools.brain_transformation import LayerMappedModel, TemporalIgnore\n",
    "from candidate_models.model_commitments import brain_translated_pool, base_model_pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-briefing",
   "metadata": {},
   "source": [
    "# Hackathon 2021 - Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-essay",
   "metadata": {},
   "source": [
    "This notebook provides a few starting points for the 2021 Brainscore Hackathon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-lewis",
   "metadata": {},
   "source": [
    "One thing to be aware of, is that the scores on the website are based on a \"private\" set of images and monkey data <sub> (= high variation set, variation 6, wider uniform distribution over transformation paramters, 2560 images) </sub>. Those aren't normally available to the public. The idea is that people can play around with \"public\" set instead, subit their model to the brainscore website, and they well use their private set to do the final evaluation. \n",
    "\n",
    "Luckily, Martin has kindly shared the private set with us, so we can replicate the website. **BUT IT MEANS SERRELAB IS NOT ALLOWED TO COMPETE IN THEIR RANKING!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-start",
   "metadata": {},
   "source": [
    "## The Brainscore Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-planet",
   "metadata": {},
   "source": [
    "The brainscore way relies heavily on identifier strings. They use a string to select the model, but also one single string to decide which dataset, which visual area, and which fitting procedure to use.\n",
    "\n",
    "For example, the code below should replicate alexnet's score for IT on the MajajHong2015 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'alexnet'\n",
    "model = brain_translated_pool[identifier]\n",
    "score = score_model(model_identifier=identifier, model=model, benchmark_identifier='dicarlo.MajajHong2015.IT-pls')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-dancing",
   "metadata": {},
   "source": [
    "The code will have first gone over all alexnet layers using the public set to select best layer. Then it used that layer for the final test with the private set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-regression",
   "metadata": {},
   "source": [
    "## Lore's Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-malawi",
   "metadata": {},
   "source": [
    "You can imagine that as soon as you want to run a couple of variations of fitting procedures, input images, etc., the identifier strings become very messy very quickly. In attempt to make things more flexible, I made a different kind of benchmark_identifiers. I also changed the score_model function to accept a bunch of kwargs. This new kind needs to start with \"tol_\". For example, I made \"tol_imagedir\" to flexibly choose which imagedir you want to extract activations for. The idea here is that the image filenames will provide the mapping between the new images and the images the monkeys saw.\n",
    "\n",
    "Some caveats:\n",
    "- The layer selection procedure will still use the brainscore defaults. It is best to select the layer to evaluate manually instead.\n",
    "- You may want to disable result caching (already off by default for the hackathon) for this way, because the kwargs make the filenames for result saving way too long\n",
    "\n",
    "For example, the code below should give the same results as the brainscor way for alexnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outside-michigan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alexnet is accessed again and reloaded\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "score_model() got an unexpected keyword argument 'assembly_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-debfb86b8cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mbaseline_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     region=region)\n\u001b[0m",
      "\u001b[0;32m/gpfs/data/tserre/irodri15/Brainscore/venv/lib/python3.7/site-packages/result_caching/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mcall_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mfunction_identifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_identifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_identifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_identifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/tserre/irodri15/Brainscore/venv/lib/python3.7/site-packages/result_caching/__init__.py\u001b[0m in \u001b[0;36mgetcallargs\u001b[0;34m(self, function, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mcall_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/runtime/opt/python/3.7.4/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetcallargs\u001b[0;34m(*func_and_positional, **named)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvarkw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                 raise TypeError(\"%s() got an unexpected keyword argument %r\" %\n\u001b[0;32m-> 1358\u001b[0;31m                                 (f_name, kw))\n\u001b[0m\u001b[1;32m   1359\u001b[0m             \u001b[0marg2value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarkw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: score_model() got an unexpected keyword argument 'assembly_name'"
     ]
    }
   ],
   "source": [
    "identifier = 'alexnet'\n",
    "model = base_model_pool[identifier]  # notice it's base_model_pool now, not brain_translated_pool\n",
    "region = 'IT'\n",
    "\n",
    "# load info about which layer to select\n",
    "with open(\"modelmeta-2019.json\", 'r') as f:\n",
    "    model_meta = json.load(f)\n",
    "layer = [i['fields']['value'] for i in model_meta if\n",
    "         i['model'] == 'benchmarks.ModelMeta' and\n",
    "         i['fields']['key'] == region+'_layer' and\n",
    "         i['fields']['model'] == identifier]\n",
    "assert (len(layer) == 1)\n",
    "layer = layer[0]\n",
    "\n",
    "# layer -> region\n",
    "model = LayerMappedModel(identifier + \"__\" + layer, activations_model=model, visual_degrees=8)\n",
    "\n",
    "model.commit(region, layer)\n",
    "\n",
    "# ignore time_bins\n",
    "model = TemporalIgnore(model)\n",
    "\n",
    "score = score_model(model_identifier=identifier,\n",
    "                    model=model,\n",
    "                    benchmark_identifier='tol_imagedir',  # benchmark that allows to flexibly set the imagedir\n",
    "                    assembly_name='dicarlo.MajajHong2015.private',  # which neural recordings are we using\n",
    "                    image_dir='image_dicarlo_hvm-private',  # based on which images' activations\n",
    "                    baseline=True,  # using random splits (the brainscore way, as apposed to custom splits)\n",
    "                    train_size=0.9,  \n",
    "                    test_size=0.1,\n",
    "                    baseline_splits=10,\n",
    "                    region=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-powder",
   "metadata": {},
   "source": [
    "The imagedir does need to be in the os.getenv('BRAINIO_HOME', ~/brainio) directory for this to work. For the hackathon, this is \"\"/media/data_cifs_lrs/projects/prj_brainscore/hackaton2021/.brainio\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
