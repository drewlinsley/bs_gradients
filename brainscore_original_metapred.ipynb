{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo \"export PYTHONPATH='$PYTHONPATH:$(pwd)/tf-models/research/slim'\" >> ~/.bashrc\n",
    "!echo \"export BRAINIO_HOME='${current_path}projects/prj_brainscore/hackaton2021/.brainio'\" >> ~/.bashrc\n",
    "!echo \"export RESULTCACHING_DISABLE='1'\" >> ~/.bashrc  \n",
    "!echo \"export CM_HOME='${current_path}projects/prj_brainscore/hackaton2021/.candidate_models'\" >> ~/.bashrc\n",
    "#\n",
    "#!pip install  git+https://github.com/brain-score/brain-score\n",
    "#!pip install  git+https://github.com/brain-score/model-tools\n",
    "#!pip install  \"candidate_models @ git+https://github.com/brain-score/candidate_models\"\n",
    "#!pip install  git+https://github.com/brain-score/brainio_base\n",
    "#!pip install  git+https://github.com/brain-score/brainio_contrib\n",
    "#!pip install  git+https://github.com/brain-score/brainio_collection\n",
    "#!pip install  git+https://github.com/brain-score/result_caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lookup from /gpfs/data/tserre/irodri15/Brainscore/serre_repos/bs_hackathon/brainio_collection/brainio_collection/lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/tserre/irodri15/Brainscore/serre_repos/bs_hackathon/brain-score/brainscore/metrics/__init__.py:37: FutureWarning: xarray subclass Score should explicitly define __slots__\n",
      "  class Score(DataAssembly):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from brainscore.benchmarks._neural_common import average_repetition, timebins_from_assembly\n",
    "from brainscore.metrics.ceiling import InternalConsistency\n",
    "from brainscore.metrics.transformations import Split\n",
    "\n",
    "from brainscore.metrics.regression import CrossRegressedCorrelation, pls_regression, pearsonr_correlation\n",
    "\n",
    "from brainio_base.assemblies import NeuroidAssembly\n",
    "from brainio_base.stimuli import StimulusSet\n",
    "from brainscore.benchmarks import BenchmarkBase, ceil_score\n",
    "from brainscore.metrics import Score\n",
    "from brainscore.model_interface import BrainModel\n",
    "from model_tools.brain_transformation import ModelCommitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_filepaths,image_size):\n",
    "    \n",
    "    return [load_image(image_filepath,image_size) for image_filepath in image_filepaths]\n",
    "\n",
    "def load_image(image_filepath,image_size):\n",
    "    \n",
    "    original_image = cv2.imread(image_filepath)\n",
    "    height, width = original_image.shape[:2]\n",
    "    transform_gen = T.ResizeShortestEdge(\n",
    "            [image_size, image_size], image_size\n",
    "        )\n",
    "    if len(original_image.shape)==2:\n",
    "        original_image = gray2rgb(original_image)\n",
    "    image = transform_gen.get_transform(original_image).apply_image(original_image)\n",
    "    with torch.no_grad():\n",
    "        image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "        inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "def load_preprocess_images2(image_filepaths, image_size=256,**kwargs):\n",
    "    #torch.cuda.empty_cache()\n",
    "    images = load_images(image_filepaths,image_size)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_brain_model(module):\n",
    "    module = __import__(module)\n",
    "    for model in module.get_model_list():\n",
    "        layers = module.get_layers(model)\n",
    "        \n",
    "        assert layers is not None\n",
    "        assert isinstance(layers, list)\n",
    "        assert len(layers) > 0\n",
    "        model = module.get_model(model)\n",
    "        assert model is not None\n",
    "        assert isinstance(model, BrainModel)\n",
    "        test_brain_model_processing(model, module)\n",
    "    print('Test successful, you are ready to submit!')\n",
    "\n",
    "\n",
    "def test_v4_processing(model, module):\n",
    "    # to be done\n",
    "    return\n",
    "\n",
    "\n",
    "def test_base_models(module):\n",
    "    module = __import__(module)\n",
    "    for model in module.get_model_list():\n",
    "        layers = module.get_layers(model)\n",
    "        print(layers)\n",
    "        assert layers is not None\n",
    "        assert isinstance(layers, list)\n",
    "        assert len(layers) > 0\n",
    "        assert module.get_model(model) is not None\n",
    "        test_processing(model, module)\n",
    "        print('Test successful, you are ready to submit!')\n",
    "\n",
    "\n",
    "def test_processing(model, module):\n",
    "    os.environ['RESULTCACHING_DISABLE'] = '1'\n",
    "    model_instance = module.get_model(model)\n",
    "    layers = module.get_layers(model)\n",
    "    brain_model = ModelCommitment(identifier=model, activations_model=model_instance,\n",
    "                                  layers=layers, region_benchmarks={'IT': ITBenchmark()})\n",
    "    brain_model.commit_region('IT')\n",
    "    benchmark = ITBenchmark()\n",
    "    score = benchmark(brain_model, do_behavior=True)\n",
    "    print(score)\n",
    "    assert score is not None\n",
    "    assert score.sel(aggregation='center')\n",
    "\n",
    "\n",
    "class ITBenchmark(BenchmarkBase):\n",
    "    def __init__(self):\n",
    "        ceiling = Score([1, np.nan], coords={'aggregation': ['center', 'error']}, dims=['aggregation'])\n",
    "        assembly_repetition = get_assembly()\n",
    "        assert len(np.unique(assembly_repetition['region'])) == 1\n",
    "        assert hasattr(assembly_repetition, 'repetition')\n",
    "        self.region = 'IT'\n",
    "        self.assembly = average_repetition(assembly_repetition)\n",
    "        self._assembly=self.assembly\n",
    "        self.timebins = timebins_from_assembly(self.assembly)\n",
    "\n",
    "        self._similarity_metric = CrossRegressedCorrelation(\n",
    "            regression=pls_regression(), correlation=pearsonr_correlation(),\n",
    "            crossvalidation_kwargs=dict(stratification_coord=Split.Defaults.stratification_coord\n",
    "            if hasattr(self.assembly, Split.Defaults.stratification_coord) else None))\n",
    "        identifier = f'{assembly_repetition.name}-layer_selection'\n",
    "        ceiler = InternalConsistency()\n",
    "        super(ITBenchmark, self).__init__(identifier=identifier, ceiling_func=lambda: ceiler(assembly_repetition), version='1.0')\n",
    "\n",
    "\n",
    "    def __call__(self, candidate: BrainModel, do_behavior=False):\n",
    "        # Do brain region task\n",
    "        candidate.start_recording(self.region, time_bins=self.timebins)\n",
    "        source_assembly = candidate.look_at(self.assembly.stimulus_set)\n",
    "        # Do behavior task\n",
    "        if do_behavior:\n",
    "            candidate.start_task(BrainModel.Task.probabilities, self.assembly.stimulus_set)\n",
    "            candidate.look_at(self.assembly.stimulus_set)\n",
    "        raw_score = self._similarity_metric(source_assembly, self.assembly)\n",
    "        print(raw_score)\n",
    "        print(ceil_score(raw_score, self.ceiling))\n",
    "        return ceil_score(raw_score, self.ceiling)\n",
    "\n",
    "class ITBenchmark(BenchmarkBase):\n",
    "    def __init__(self):\n",
    "        ceiling = Score([1, np.nan], coords={'aggregation': ['center', 'error']}, dims=['aggregation'])\n",
    "        assembly_repetition = get_assembly()\n",
    "        assert len(np.unique(assembly_repetition['region'])) == 1\n",
    "        assert hasattr(assembly_repetition, 'repetition')\n",
    "        self.region = 'IT'\n",
    "        self.assembly = average_repetition(assembly_repetition)\n",
    "        self._assembly=self.assembly\n",
    "        self.timebins = timebins_from_assembly(self.assembly)\n",
    "\n",
    "        self._similarity_metric = CrossRegressedCorrelation(\n",
    "            regression=pls_regression(), correlation=pearsonr_correlation(),\n",
    "            crossvalidation_kwargs=dict(stratification_coord=Split.Defaults.stratification_coord\n",
    "            if hasattr(self.assembly, Split.Defaults.stratification_coord) else None))\n",
    "        identifier = f'{assembly_repetition.name}-layer_selection'\n",
    "        ceiler = InternalConsistency()\n",
    "        super(ITBenchmark, self).__init__(identifier=identifier, ceiling_func=lambda: ceiler(assembly_repetition), version='1.0')\n",
    "\n",
    "\n",
    "    def __call__(self, candidate: BrainModel, do_behavior=False):\n",
    "        # Do brain region task\n",
    "        candidate.start_recording(self.region, time_bins=self.timebins)\n",
    "        source_assembly = candidate.look_at(self.assembly.stimulus_set)\n",
    "        # Do behavior task\n",
    "        if do_behavior:\n",
    "            candidate.start_task(BrainModel.Task.probabilities, self.assembly.stimulus_set)\n",
    "            candidate.look_at(self.assembly.stimulus_set)\n",
    "        raw_score = self._similarity_metric(source_assembly, self.assembly)\n",
    "        print(raw_score)\n",
    "        print(ceil_score(raw_score, self.ceiling))\n",
    "        return ceil_score(raw_score, self.ceiling)\n",
    "    \n",
    "def get_assembly():\n",
    "    image_names = []\n",
    "    for i in range(1, 21):\n",
    "        image_names.append(f'images/{i}.png')\n",
    "    assembly = NeuroidAssembly((np.arange(40 * 5) + np.random.standard_normal(40 * 5)).reshape((5, 40, 1)),\n",
    "                               coords={'image_id': (\n",
    "                                   'presentation',\n",
    "                                   image_names * 2),\n",
    "                                   'object_name': ('presentation', ['a'] * 40),\n",
    "                                   'repetition': ('presentation', ([1] * 20 + [2] * 20)),\n",
    "                                   'neuroid_id': ('neuroid', np.arange(5)),\n",
    "                                   'region': ('neuroid', ['IT'] * 5),\n",
    "                                   'time_bin_start': ('time_bin', [70]),\n",
    "                                   'time_bin_end': ('time_bin', [170])\n",
    "                               },\n",
    "                               dims=['neuroid', 'presentation', 'time_bin'])\n",
    "    labels = ['a'] * 10 + ['b'] * 10\n",
    "    stimulus_set = StimulusSet([{'image_id': image_names[i], 'object_name': 'a', 'image_label': labels[i]}\n",
    "                                for i in range(20)])\n",
    "    stimulus_set.image_paths = {image_name: os.path.join(os.path.dirname(__file__), image_name)\n",
    "                                for image_name in image_names}\n",
    "    stimulus_set.name = 'test'\n",
    "    assembly.attrs['stimulus_set'] = stimulus_set\n",
    "    assembly.attrs['stimulus_set_name'] = stimulus_set.name\n",
    "    assembly = assembly.squeeze(\"time_bin\")\n",
    "    return assembly.transpose('presentation', 'neuroid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    \"\"\"\n",
    "    This method fetches an instance of a base model. The instance has to be callable and return a xarray object,\n",
    "    containing activations. There exist standard wrapper implementations for common libraries, like pytorch and\n",
    "    keras. Checkout the examples folder, to see more. For custom implementations check out the implementation of the\n",
    "    wrappers.\n",
    "    :param name: the name of the model to fetch\n",
    "    :return: the model instance\n",
    "    \"\"\"\n",
    "    print(name)\n",
    "    cfg = setup(name)\n",
    "    image_size = cfg.MIN_SIZE_TEST\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    model = predictor.model\n",
    "    preprocessing = functools.partial(load_preprocess_images2,image_size=image_size)\n",
    "    wrapper = PytorchWrapper(identifier=name, model=model, preprocessing=preprocessing)\n",
    "    wrapper.image_size = image_size\n",
    "    return wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
